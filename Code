model = total;

%% Pixel size & Slice thickness
pixelW = 0.977;
slice = 3;
%%
model_crop_size = size(model);
% resize to obtain a volume with pixel size=1 and slice thickness=1
model = imresize3(model,'scale',[pixelW,pixelW,slice]); 
%model = imresize3(model, k.*model_crop_size, 'nearest');

%% Increasing model images contrast for producing binary images
contrast_increase_constant = 1;
contrast_increased_model = contrast_increase_constant * model;


%% Generating Gray Scale Volumetric Image
gray_scale_model = uint8(floor(256*model));

%% Binarizing model slices
binary_model = imbinarize(contrast_increased_model);

%% Calculating stats of 3d model
stats = regionprops3(binary_model,gray_scale_model,"all");

%% Generating mesh
model_size = size(model);
x = 1:model_size(2);
y = 1:model_size(1);
z = 1:model_size(3);
[X,Y,Z] = meshgrid(x,y,z);
[F, V] = MarchingCubes(single(X), single(Y), single(Z), model, 0.5);
%mesh_surface = isosurface(X,Y,Z,model);

%% Volume (voxel_counting)
params.volume = stats.Volume;

%% Volume (mesh)
face_volume_summation = 0;
number_of_faces = size(F);

for i = 1:number_of_faces
    face = F(i,:);
    v1 = V(face(1),:);
    v2 = V(face(2),:);
    v3 = V(face(3),:);
    volume_of_face = (dot(v1,cross(v2,v3)))/6;
    face_volume_summation = face_volume_summation + volume_of_face;
end


params.volume_mesh = abs(face_volume_summation);

%% Surface area (mesh)
face_area_summation = 0;
number_of_faces = size(V);

for i = 1:number_of_faces
    face = F(i,:);
    v1 = V(F(1),:);
    v2 = V(F(2),:);
    v3 = V(F(3),:);
    area_of_face = (0.5*norm(cross((v2-v1),(v3-v1))));
    face_area_summation = face_area_summation + area_of_face;
end


params.surface_area_mesh = face_area_summation;

%% Compactness 1
params.compactness_1 = params.volume / (sqrt(pi*(params.surface_area^3)));

%% 8.Compactness 2
params.compactness_2 = 36*pi*((params.volume^2)/(params.surface_area^3));

%% Spherical disproportion
params.spherical_disproportion = ...
    params.surface_area/((36*pi*(params.volume_mesh^2))^(1/3));

%% Sphericity
params.sphericity = 1/params.spherical_disproportion;

%% Asphericity
params.asphericity = ...
    (((params.surface_area^3)/((36*pi*(params.volume^2))))^(1/3))-1;

%% Maximum 3D diameter
convex_hull = stats.ConvexHull{1,1};
max_norm_resualt =0;
count = length(stats.ConvexHull{1,1}(:,1));
for z = 1:count
    
    for y = 1:count
        if z ~= y
            x = (norm(convex_hull(z,:)-convex_hull(y,:)));
            if x > max_norm_resualt
                max_norm_resualt = x;
            else
                continue
            end
        else
            continue
        end
    end
end
params.maximum_3d_diameter = max_norm_resualt;

%% Maximum 2D diameter (row)
convex_hull=stats.ConvexHull{1,1};
convex_hull_row = stats.ConvexHull{1,1}(:,1);
max_norm_resualt_row =0;
count = length(stats.ConvexHull{1,1}(:,1));
for z = 1:count
    for y = 1:count
        if convex_hull_row(y)== convex_hull_row(z)
            dist_slice = norm(convex_hull(y,:)-convex_hull(z,:));
            if dist_slice > max_norm_resualt_row
                max_norm_resualt_row = dist_slice;
            else
                continue
            end
        else
            continue
        end
        
    end
end




import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load dataset (for example purposes, let's use the Iris dataset)
from sklearn.datasets import load_iris
data = load_iris()
X, y = data.data, data.target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize models
svm_model = SVC()
rf_model = RandomForestClassifier()
lr_model = LogisticRegression()
knn_model = KNeighborsClassifier()

# Train the models
svm_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)
lr_model.fit(X_train, y_train)
knn_model.fit(X_train, y_train)

# Make predictions
svm_predictions = svm_model.predict(X_test)
rf_predictions = rf_model.predict(X_test)
lr_predictions = lr_model.predict(X_test)
knn_predictions = knn_model.predict(X_test)

# Evaluate the models
svm_accuracy = accuracy_score(y_test, svm_predictions)
rf_accuracy = accuracy_score(y_test, rf_predictions)
lr_accuracy = accuracy_score(y_test, lr_predictions)
knn_accuracy = accuracy_score(y_test, knn_predictions)

# Print accuracy and classification report for each model
print("Support Vector Machine Accuracy:", svm_accuracy)
print(classification_report(y_test, svm_predictions))

print("Random Forest Accuracy:", rf_accuracy)
print(classification_report(y_test, rf_predictions))

print("Logistic Regression Accuracy:", lr_accuracy)
print(classification_report(y_test, lr_predictions))

print("K-Nearest Neighbors Accuracy:", knn_accuracy)
print(classification_report(y_test, knn_predictions))


